---
description: Orchestrate full SpecKit Plus workflow for Python chapters (12-29). Automatically chains /sp.specify ‚Üí /sp.plan ‚Üí /sp.tasks with approval gates. Students learn Python through AIDD thinking (specification-first, validation-first, AI partnership).
---

# /sp.python-chapter: Orchestrated Python Chapter Workflow

**Purpose**: Design a complete Python chapter (12-29) using AIDD principles with **automatic orchestration** of the full SpecKit Plus workflow (Spec ‚Üí Plan ‚Üí Tasks ‚Üí optional Implementation). Students learn programming by applying AIDD thinking learned in Chapters 1-11.

## User Input

```text
$ARGUMENTS
```

## VERTICAL INTELLIGENCE: AIDD-Driven Python Teaching

Before orchestration begins, understand what makes Python chapters effective in the AI-native era:

### Core Principle: Specification-First, Validation-First, AI Partnership

Students don't memorize Python syntax. Instead:

1. **Understand the concept** (plain language explanation)
2. **See minimal code** (what it does in action)
3. **Ask their AI** (explore through dialogue with Claude Code/Gemini CLI)
4. **Extract insight** (why this matters for thinking, not just coding)

### AIDD Thinking Applied to Programming

**Traditional Programming Teaching**:
- "Memorize Python syntax"
- "Here are all 47 string methods"
- Syntax-first (memorize, then apply)

**AIDD-First Python Learning**:
- "Understand concepts first, then use code as a tool"
- "Here's what you need; your AI shows how when needed"
- Understanding-first (understand, then code)
- Specification-first (clarify intent, then code)
- Validation-first (test understanding, not syntax)

### Teaching Pattern (Every Concept)

```markdown
## 1. [Concept Name] ‚Äî [Why it matters]

**What it is:**
Plain-language explanation (2-3 sentences).

### üíª Code Idea

\`\`\`python
# Minimal code showing the concept
# Focus on WHAT it does
\`\`\`

### ü§ñ Think With Your AI

> "What does this do?"
>
> "What changes if we...?"
>
> "How would you use this to...?"

### üß† The Reasoning Pattern

[Why this concept matters for thinking, not just coding]
```

**Example:**

```markdown
## 1. Variables ‚Äî Storing Data

**What it is:**
A variable names a value so your program can remember it.

### üíª Code Idea

\`\`\`python
name = "Alex"
score = 95
\`\`\`

### ü§ñ Think With Your AI

> "Why do we need variables instead of just using 95?"
>
> "What breaks if we forget to name a value?"
>
> "How do AI agents use variables to track context?"

### üß† The Reasoning Pattern

Programs need memory. Variables let you say "remember this as X"‚Äî
exactly how reasoning chains in AI maintain state.
```

---

## Python Standards (Chapters 12-29)

**Version:** 3.14+ (always use latest stable release from https://www.python.org/downloads/)
**Syntax:** f-strings only, match/case (17+), modern types (`list[int]`, `X | None`)
**Type hints:** Core (Ch 13) ‚Üí Gradual Application (14-26) ‚Üí Mandatory (27+)
**Note on Type Hints:** Modern Python treats type hints as essential for clarity and specification-first thinking, not optional features. Integrate from Chapter 13 onwards.

**Security (non-negotiable):**
- ‚ùå No `eval()`, `shell=True`, hardcoded secrets
- ‚úÖ Environment variables, input validation, modern patterns

---

## CRITICAL DESIGN RULES

### Rule 1: USER INTENT IS AUTHORITY

**Never override user input:**
- User says "beginner" ‚Üí Make A1-A2 (NOT A2-B1)
- User says "just variables" ‚Üí Only variables (NOT + functions + loops)
- User says "absolute beginners" ‚Üí 5 concepts max, simple framing

**Always ask, always honor. Do NOT assume.**

---

### Rule 2: NO FORWARD REFERENCES

**Never mention untaught concepts:**
- ‚ùå NO Chapter 30+ references
- ‚ùå NO "Spec-Driven Development" (not yet taught)
- ‚ùå NO methodology beyond AIDD

**DO reference AIDD (Ch 1-11, already taught):**
- ‚úÖ "Apply the specification-first thinking from Chapter 4..."
- ‚úÖ "Recall the nine pillars of AIDD from Chapter 4..."
- ‚úÖ "Use validation-first thinking when testing your code..."

---

### Rule 3: RUTHLESS CONTEXT FILTERING

**When extracting from context materials:**

**Chapter 13 "Introduction to Python":**
- ‚úÖ "What is Python?" ‚Üí USE (intro concept)
- ‚úÖ "Your first program" ‚Üí USE (intro outcome)
- ‚ùå "Functions" ‚Üí SKIP (Ch 20 topic)
- ‚ùå "Classes" ‚Üí SKIP (Ch 24+ topic)
- ‚ùå "Async/await" ‚Üí SKIP (Ch 28 topic)

**Chapter 17 "Control Flow and Loops":**
- ‚úÖ "if/elif/else statements" ‚Üí USE (chapter focus)
- ‚úÖ "for loops" ‚Üí USE (chapter focus)
- ‚ùå "Functions" ‚Üí SKIP (Ch 20 topic)
- ‚ùå "List comprehensions" ‚Üí SKIP (advanced)
- ‚ùå "Exception handling" ‚Üí SKIP (Ch 21 topic)

**Decision Rule:**
- IF context concept fits THIS chapter's title ‚Üí EXTRACT
- IF context concept belongs to Ch N+1 or later ‚Üí SKIP
- IF context concept is advanced variation ‚Üí SKIP
- IF context concept requires future prerequisites ‚Üí SKIP

---

### Rule 4: MINIMAL SCOPE

**Depth > breadth.**

- Beginner (Ch 12-16): 5 concepts max, 3-4 lessons
- Intermediate (Ch 17-23): 7 concepts max, 4-5 lessons
- Advanced (Ch 24-29): 10 concepts max, 5-6 lessons

---

### Rule 5: MINIMAL FILES

**Create ONLY:**
- ‚úÖ spec.md (what students learn)
- ‚úÖ plan.md (how we teach it)
- ‚úÖ tasks.md (implementation checklist)

**Never create:**
- ‚ùå index.md, _templates/, _assets/, _code-examples/, lesson-template.md, capstone-rubric.md

---

### Rule 6: TROUBLESHOOTING IS AI PARTNERSHIP

**Real-world context:** In an AI-native world, students will encounter errors (installation, syntax, environment issues). Rather than detailed troubleshooting in every chapter, teach students to ASK their AI assistant.

**Application in chapters:**
- **Installation/Setup chapters**: Include prompt like: `"I tried to install Python but got this error: [error]. What does this mean and how do I fix it?"`
- **Execution chapters**: Include prompt like: `"My program runs but gives this output. Is this correct? Why?"`
- **Advanced chapters**: Include prompt like: `"I'm getting a TypeError. Walk me through what went wrong."`

**Why this works:**
- ‚úÖ Teaches resilience: Errors are information to be understood, not obstacles
- ‚úÖ Builds partnership: AI becomes problem-solving collaborator, not just code generator
- ‚úÖ Scales with complexity: Works for simple errors (Python not found) to complex errors (type mismatches)
- ‚úÖ Honors reality: Professional developers ask AI for error help constantly

**Example (from Chapter 13, Lesson 2):**
```markdown
### Prompt 2: Troubleshoot Installation Errors
\`\`\`
I tried to install Python but got this error: [describe your error].
What does this mean and how do I fix it?
\`\`\`

**Expected outcome**: AI explains the error and provides step-by-step fixing instructions.
```

This single prompt replaces 10 pages of platform-specific troubleshooting guides that become outdated.

---

### Rule 7: STANDARDIZED "TRY WITH AI" FORMAT

**Every lesson MUST end with "Try With AI" section** following this exact structure (verified in Chapter 1 and Chapter 13):

```markdown
## Try With AI

Use your AI companion (Claude Code or Gemini CLI). [Brief context about what you're exploring].

### Prompt 1: [Descriptive Title]
\`\`\`
[Clear, concrete prompt asking about the concept]
\`\`\`

**Expected outcome**: [What student should understand after AI response]

### Prompt 2: [Descriptive Title]
\`\`\`
[Clear, concrete prompt asking about application or edge case]
\`\`\`

**Expected outcome**: [What student learns from this]

### Prompt 3: [Descriptive Title]
\`\`\`
[Prompt encouraging deeper understanding or connection to real-world use]
\`\`\`

**Expected outcome**: [Connection to AIDD or professional practice]

### Prompt 4: [Descriptive Title]
\`\`\`
[Synthesis prompt pulling together concepts from lesson]
\`\`\`

**Expected outcome**: [Integration of understanding]
```

**Critical requirements:**
- ‚úÖ Exactly 4 prompts per lesson (progressive complexity)
- ‚úÖ Prompts are CONCRETE and SPECIFIC (not "ask AI about X")
- ‚úÖ Each prompt has explicit "Expected outcome" describing what student learns
- ‚úÖ Prompts should include rubric-style validation ("Does this answer your spec?")
- ‚úÖ No "Key Takeaways" or "Summary" sections after "Try With AI"
- ‚úÖ "Try With AI" is the final substantive section (closure point)

**Why this matters:**
- Consistency across entire book (students know the format)
- Progressive prompts teach exploration, not memorization
- "Expected outcome" sets clear learning targets
- Validates understanding without artificial quizzes

---

## ORCHESTRATED WORKFLOW (What Actually Happens)

When you run `/sp.python-chapter [N]`:

### PHASE 0: Context Gathering (Interactive)

1. **Validate chapter**: Read `specs/book/chapter-index.md` and extract chapter title (ANCHOR)
2. **Ask 4 questions**:
   - Who are we teaching? (audience ‚Üí complexity tier)
   - What's the core focus for THIS chapter? (scope ‚Üí concept limit)
   - What can students BUILD? (outcome ‚Üí learning objective)
   - Which context aspects fit? (materials ‚Üí pedagogical patterns)
3. **Store responses** for next phases

**Apply AIDD**: Specification-first means understanding WHO and WHAT before designing HOW.

---

### PHASE 1: Specification (Automated)

```
‚Üí Invoke: /sp.specify [chapter-context]
  ‚îú‚îÄ Pass: chapter number, title, user answers, context materials
  ‚îú‚îÄ Apply: AIDD principles, cognitive load limits, teaching patterns
  ‚îú‚îÄ Create: specs/part-5-chapter-[N]/spec.md
  ‚îî‚îÄ Report: "Spec created. Review and approve."

WAIT: User reviews spec.md
‚Üí User confirms: "‚úÖ Spec approved" or provides feedback
  ‚îú‚îÄ If feedback: Update spec.md iteratively
  ‚îî‚îÄ If approved: Continue to PHASE 2
```

**What /sp.specify receives:**
- Chapter title (anchor from chapter-index.md)
- User's audience answer (determines complexity tier: A1/A2/B1)
- User's scope answer (limits concepts to 5/7/10)
- User's outcome answer (real thing students will build)
- Context materials (extracted pedagogically)
- AIDD principles (specification-first, validation-first, AI partnership)
- Teaching pattern template (What it is ‚Üí Code ‚Üí Try ‚Üí Why it matters)
- Cognitive load limits (max 5 for beginner, 7 for intermediate, 10 for advanced)

---

### PHASE 2: Planning (Automated)

```
‚Üí Invoke: /sp.plan [spec-context]
  ‚îú‚îÄ Read: specs/part-5-chapter-[N]/spec.md
  ‚îú‚îÄ Apply: Lesson progression, CEFR proficiency levels, AI prompts
  ‚îú‚îÄ Create: specs/part-5-chapter-[N]/plan.md
  ‚îî‚îÄ Report: "Plan created. Review and approve."

WAIT: User reviews plan.md
‚Üí User confirms: "‚úÖ Plan approved" or provides feedback
  ‚îú‚îÄ If feedback: Update plan.md iteratively
  ‚îî‚îÄ If approved: Continue to PHASE 3
```

**What /sp.plan receives:**
- Approved spec.md (learning objectives, concepts, success criteria)
- Chapter scope (what fits this chapter, what doesn't)
- AIDD teaching pattern (Concept ‚Üí Code ‚Üí Try ‚Üí Why)
- Proficiency expectations (CEFR A1/A2/B1 levels)
- Real outcome students will build

---

### PHASE 3: Tasks (Automated)

```
‚Üí Invoke: /sp.tasks [spec+plan-context]
  ‚îú‚îÄ Read: specs/part-5-chapter-[N]/spec.md + plan.md
  ‚îú‚îÄ Apply: Acceptance criteria, validation steps, implementation checklist
  ‚îú‚îÄ Create: specs/part-5-chapter-[N]/tasks.md
  ‚îî‚îÄ Report: "Tasks created. Review and approve."

WAIT: User reviews tasks.md
‚Üí User confirms: "‚úÖ Tasks approved" or provides feedback
  ‚îú‚îÄ If feedback: Update tasks.md iteratively
  ‚îî‚îÄ If approved: Continue to PHASE 4
```

**What /sp.tasks receives:**
- Approved spec.md + plan.md (complete design)
- Learning objectives (what success looks like)
- Lessons (what needs to be implemented)
- Acceptance criteria (how to validate)

---

### PHASE 4: Implementation (Optional)

```
‚Üí Ask user: "Ready to implement lesson content?"

Options:
A) Implement with lesson-writer subagent
   ‚Üí Invoke: lesson-writer subagent
   ‚Üí Pass: spec.md, plan.md, tasks.md
   ‚Üí Apply: AIDD teaching pattern, CEFR levels, validation-first approach
   ‚Üí Create: docs/part-5/chapter-[N]/{01,02,03,04}-lesson-*.md

B) Manual implementation
   ‚Üí User implements using tasks.md as checklist

C) Done for now
   ‚Üí Keep design artifacts, skip implementation

‚Üí Report final status
```

---

## KEY PRINCIPLES (Always Applied)

### ‚úÖ AIDD-First
- Reinforce specification-first thinking from Chapters 1-11
- Validation-first practice: "How will students test understanding?"
- AI partnership: "How will they use Claude Code/Gemini CLI?"

### ‚úÖ No Forward References
- Zero mentions of Chapters 30+ (SDD taught later)
- No concepts from future chapters
- Chapter title from `chapter-index.md` is the absolute anchor

### ‚úÖ Honors User Intent
- User's audience choice = final decision (never override)
- User's scope answer = limits concepts (never expand)
- User's outcome answer = determines lessons (never modify)

### ‚úÖ Ruthless Context Filtering
- Only extract context matching THIS chapter's title
- Skip concepts from future chapters (even if in materials)
- Skip advanced variations and tangential concepts

### ‚úÖ Cognitive Load Limits
- Max 5 concepts for beginner (Ch 12-16)
- Max 7 concepts for intermediate (Ch 17-23)
- Max 10 concepts for advanced (Ch 24-29)

### ‚úÖ Teaching Intelligence Preserved
- Every phase applies AIDD principles
- Every phase uses teaching patterns
- Every phase respects chapter boundaries
- Every phase validates against acceptance criteria

---

## EXECUTION INSTRUCTIONS (For Claude Code)

**CRITICAL**: This is an EXECUTABLE orchestration prompt, not documentation. Claude Code must:
1. Follow this flow exactly, in this order
2. Automatically invoke downstream commands WITHOUT asking for approval first
3. Pass full context (AIDD principles, teaching patterns) to each command
4. Respect approval gates ONLY between phases (not before first invocation)

### THE ORCHESTRATED WORKFLOW (EXECUTABLE)

#### PHASE 0: Validation & Context Gathering (Interactive)

1. **Read and validate chapter number**:
   - Read: `specs/book/chapter-index.md`
   - Extract chapter title for chapters 12-29 only
   - Reject if chapter < 12 or > 29
   - Store: `chapter_title`, `chapter_num`, `part_num` (derived from chapter)

2. **Ask 4 clarifying questions** (Interactive user input):
   ```
   Q1: Who is the primary audience for Chapter [N]: [Title]?
   Q2: What is the core focus for THIS chapter ONLY?
   Q3: What should students be able to BUILD by the end?
   Q4: How should this chapter emphasize AIDD principles?
   ```
   - Store all 4 answers in context
   - Apply AIDD thinking: Specification-first means understanding WHO and WHAT before HOW

3. **Create feature branch** (Automatic, NO USER INTERACTION):
   ```bash
   git checkout -b [branch-name]
   ```
   Where `[branch-name]` = `[NN]-chapter-title-slug` (e.g., `013-introduction-to-python`)

---

#### PHASE 1: Specification (Automated + Intelligent)

**THIS PHASE INVOKES `/sp.specify` AUTOMATICALLY WITH FULL CONTEXT**

1. **Prepare context** (Ruthless filtering applied):
   - Gather user's 4 answers from PHASE 0
   - Extract materials from `context/13_chap12_to_29_specs/` (if they exist)
   - Apply ruthless filtering: Skip future chapters, skip advanced variations, skip tangential concepts
   - Embed AIDD principles in the context
   - Embed teaching patterns in the context
   - Embed cognitive load limits (5 for beginner, 7 for intermediate, 10 for advanced)

2. **Invoke /sp.specify with full context**:
   ```
   /sp.specify [chapter-slug]

   Write Chapter [N]: [Title] in Part [P]

   [Full AIDD context, user answers, teaching patterns, cognitive load rules, ruthlessly filtered context materials]
   ```

3. **Wait for /sp.specify completion**:
   - ‚úÖ `specs/part-[P]-chapter-[N]/spec.md` is created
   - ‚úÖ AIDD principles applied
   - ‚úÖ Teaching patterns specified
   - ‚úÖ Learning objectives aligned with evals

4. **Output approval checkpoint**:
   ```
   ‚úÖ PHASE 1 COMPLETE: Specification Created

   üìã specs/part-[P]-chapter-[N]/spec.md

   Please review and confirm:
   - ‚úÖ "Spec approved" to proceed to planning
   - üìù Feedback to revise specification
   - ‚ùì Questions for clarification
   ```

5. **Wait for user approval**: Block here until user confirms "‚úÖ Spec approved" OR provides feedback

---

#### PHASE 2: Planning (Automated + Intelligent) - Triggered After Spec Approval

**THIS PHASE INVOKES `/sp.plan` AUTOMATICALLY WITH FULL CONTEXT**

1. **Prepare context** (Read approved spec, add intelligence):
   - Read: `specs/part-[P]-chapter-[N]/spec.md` (the approved specification)
   - Extract: Learning objectives, key concepts, success criteria
   - Add: CEFR proficiency levels (A1/A2/B1 based on audience)
   - Add: Lesson progression rules (foundational ‚Üí applied ‚Üí why it matters)
   - Add: AI prompts for each lesson (specification-first, validation-first)
   - Add: Teaching pattern structure for every lesson

2. **Invoke /sp.plan with full context**:
   ```
   /sp.plan [chapter-slug]

   [Full context from spec, CEFR levels, lesson structure, AIDD teaching patterns]
   ```

3. **Wait for /sp.plan completion**:
   - ‚úÖ `specs/part-[P]-chapter-[N]/plan.md` is created
   - ‚úÖ Lessons broken down lesson-by-lesson
   - ‚úÖ CEFR proficiency levels assigned
   - ‚úÖ AI prompts specified

4. **Output approval checkpoint**:
   ```
   ‚úÖ PHASE 2 COMPLETE: Plan Created

   üìã specs/part-[P]-chapter-[N]/plan.md

   Please review and confirm:
   - ‚úÖ "Plan approved" to proceed to tasks
   - üìù Feedback to revise plan
   - ‚ùì Questions for clarification
   ```

5. **Wait for user approval**: Block here until user confirms "‚úÖ Plan approved" OR provides feedback

---

#### PHASE 3: Tasks (Automated + Intelligent) - Triggered After Plan Approval

**THIS PHASE INVOKES `/sp.tasks` AUTOMATICALLY WITH FULL CONTEXT**

1. **Prepare context** (Read approved spec + plan, add validation):
   - Read: `specs/part-[P]-chapter-[N]/spec.md` (learning objectives)
   - Read: `specs/part-[P]-chapter-[N]/plan.md` (lesson structure)
   - Add: Acceptance criteria for each lesson
   - Add: Validation steps (how to test understanding)
   - Add: Implementation checklist (content requirements)

2. **Invoke /sp.tasks with full context**:
   ```
   /sp.tasks [chapter-slug]

   [Full context from spec + plan, acceptance criteria, validation steps]
   ```

3. **Wait for /sp.tasks completion**:
   - ‚úÖ `specs/part-[P]-chapter-[N]/tasks.md` is created
   - ‚úÖ Implementation checklist defined
   - ‚úÖ Validation steps specified

4. **Output completion report**:
   ```
   ‚úÖ ALL DESIGN ARTIFACTS COMPLETE

   üìã specs/part-[P]-chapter-[N]/spec.md
   üìã specs/part-[P]-chapter-[N]/plan.md
   üìã specs/part-[P]-chapter-[N]/tasks.md
   ```

5. **Ask for next step**:
   ```
   Ready to implement?

   A) Implement with lesson-writer subagent
   B) Manual implementation (use tasks.md as checklist)
   C) Done for now (keep designs, skip implementation)
   ```

---

#### PHASE 4: Implementation (Optional) - Triggered Only If User Chooses A

**THIS PHASE INVOKES lesson-writer subagent IF AND ONLY IF USER CHOOSES OPTION A**

1. **Prepare context** (Read all 3 approved artifacts):
   - Read: `specs/part-[P]-chapter-[N]/spec.md`
   - Read: `specs/part-[P]-chapter-[N]/plan.md`
   - Read: `specs/part-[P]-chapter-[N]/tasks.md`
   - Add: AIDD teaching pattern (What it is ‚Üí Code ‚Üí Try ‚Üí Why it matters)
   - Add: CEFR levels for validation
   - Add: Validation-first approach (test understanding before moving on)

2. **Invoke lesson-writer subagent** (Only if user chose Option A):
   ```
   Task(
       subagent_type="lesson-writer",
       prompt=prepare_lesson_writer_prompt(
           spec, plan, tasks,
           aidd_teaching_pattern=True,
           cefr_levels=True,
           validation_first=True
       )
   )
   ```

3. **Wait for lesson-writer completion**:
   - ‚úÖ `docs/part-[P]/chapter-[N]/{01,02,03,04}-lesson-*.md` created
   - ‚úÖ Full AIDD methodology applied
   - ‚úÖ AI partnership approach emphasized

4. **Final report**:
   ```
   ‚úÖ CHAPTER [N] IMPLEMENTATION COMPLETE

   üìö Lessons created in: docs/part-[P]/chapter-[N]/

   Next steps:
   - Test each lesson interactively
   - Run technical-reviewer validation
   - Prepare for publication
   ```

---

### CRITICAL EXECUTION RULES

1. **Sequential Invocation**: Phases execute in order (0 ‚Üí 1 ‚Üí 2 ‚Üí 3 ‚Üí 4), never out of order
2. **Automatic Chaining**: Each phase automatically invokes the next command (no "ask user first")
3. **Approval Gates Only Between Phases**: User approves AFTER each phase completes, BEFORE next phase starts
4. **Context Preservation**: Each phase reads prior phase outputs and passes them forward
5. **Vertical Intelligence Embedded**: EVERY command invocation includes AIDD principles, teaching patterns, cognitive load rules
6. **Ruthless Filtering**: Materials from future chapters are SKIPPED, not extracted
7. **No User Override**: User intent (audience, scope, outcome) is NEVER overridden, only honored
8. **Feature Branch Creation**: Automatic checkout of feature branch in PHASE 0, before any other work
9. **All 3 Artifacts Required**: Spec, Plan, and Tasks must exist before implementation can proceed

---

## CRITICAL VALIDATION (Before Each Phase)

**PHASE 1 Validation** (before `/sp.specify`):
- ‚úÖ Chapter number valid (12-29)
- ‚úÖ Chapter title matches `chapter-index.md`
- ‚úÖ User's audience answer captured
- ‚úÖ User's scope answer captured
- ‚úÖ User's outcome answer captured
- ‚úÖ Context will be ruthlessly filtered
- ‚úÖ AIDD principles will be applied

**PHASE 2 Validation** (before `/sp.plan`):
- ‚úÖ spec.md was created successfully
- ‚úÖ Concept count ‚â§ tier limit (5/7/10)
- ‚úÖ No forward references (Chapters 30+)
- ‚úÖ No methodology names (except AIDD for reinforcement)
- ‚úÖ Only Chapters 1-N are prerequisites
- ‚úÖ Teaching pattern respected

**PHASE 3 Validation** (before `/sp.tasks`):
- ‚úÖ plan.md was created successfully
- ‚úÖ Lessons match spec's learning objectives
- ‚úÖ Proficiency levels assigned (CEFR)
- ‚úÖ AI prompts specified for each lesson
- ‚úÖ Validation points defined

**PHASE 4 Validation** (before lesson-writer):
- ‚úÖ All 3 design files exist and are valid
- ‚úÖ User chose implementation option
- ‚úÖ Context filtered ruthlessly
- ‚úÖ AIDD principles embedded
- ‚úÖ Ready for lesson content creation

---

## WHAT GETS CREATED

**By End of PHASE 3** (mandatory):
```
specs/part-5-chapter-[N]/
  ‚îú‚îÄ‚îÄ spec.md       (What students learn + AIDD principles)
  ‚îú‚îÄ‚îÄ plan.md       (How we teach it, lesson-by-lesson + CEFR levels)
  ‚îî‚îÄ‚îÄ tasks.md      (Implementation checklist + validation)
```

**By End of PHASE 4** (if Option A chosen):
```
docs/part-5/chapter-[N]/
  ‚îú‚îÄ‚îÄ 01-lesson-1-[topic].md
  ‚îú‚îÄ‚îÄ 02-lesson-2-[topic].md
  ‚îú‚îÄ‚îÄ 03-lesson-3-[topic].md
  ‚îú‚îÄ‚îÄ 04-lesson-4-[topic].md (or more, based on plan)
  ‚îî‚îÄ‚îÄ index.md (auto-generated TOC)
```

---

## EXAMPLE EXECUTION (What User Sees)

```
> /sp.python-chapter 13

‚è∫ PHASE 0: Context Gathering

Chapter 13: "Introduction to Python" (Part 5)
Prerequisites: Chapters 1-12 (AIDD principles + tools)

Q1: Who are we teaching?
[User answers: Absolute beginners AND professionals transitioning to AI-native]

Q2: Core focus for THIS chapter?
[User answers: Introduction fundamentals + first program]

Q3: What will students BUILD?
[User answers: Interactive program asking for name and printing greeting]

Q4: Which context aspects from materials?
[User answers: Use existing lesson structure but adapt for AIDD principles]

‚úÖ Context gathered. Moving to PHASE 1...

---

‚è∫ PHASE 1: Specification (Automated)

Invoking: /sp.specify with chapter context...
Applying: AIDD principles, teaching patterns, cognitive load limits

[/sp.specify generates spec.md]

üìã Spec created: specs/part-5-chapter-13/spec.md

Please review the specification:
- Does this match your vision for Chapter 13?
- Are learning objectives clear?
- Is scope appropriate (not too broad)?
- Are AIDD principles reinforced?

Reply with: "‚úÖ Spec approved" or provide feedback

[User: ‚úÖ Spec approved]

‚úÖ Spec approved. Moving to PHASE 2...

---

‚è∫ PHASE 2: Planning (Automated)

Invoking: /sp.plan with approved spec...
Applying: Lesson progression, CEFR levels, AI prompts

[/sp.plan generates plan.md]

üìã Plan created: specs/part-5-chapter-13/plan.md

Please review the lesson breakdown:
- Are 3-4 lessons appropriate?
- Are AI prompts specified for each lesson?
- Are CEFR proficiency levels correct (A1 for intro)?
- Is AIDD teaching pattern applied?

Reply with: "‚úÖ Plan approved" or provide feedback

[User: ‚úÖ Plan approved]

‚úÖ Plan approved. Moving to PHASE 3...

---

‚è∫ PHASE 3: Tasks (Automated)

Invoking: /sp.tasks with spec + plan...
Applying: Validation points, acceptance criteria, testing

[/sp.tasks generates tasks.md]

üìã Tasks created: specs/part-5-chapter-13/tasks.md

Please review the implementation checklist:
- Are acceptance criteria clear?
- Are validation steps included?
- Are all lesson phases covered?

Reply with: "‚úÖ Tasks approved" or provide feedback

[User: ‚úÖ Tasks approved]

‚úÖ Tasks approved. Moving to PHASE 4...

---

‚è∫ PHASE 4: Implementation (Optional)

All design artifacts complete:
  ‚úÖ specs/part-5-chapter-13/spec.md (AIDD-driven)
  ‚úÖ specs/part-5-chapter-13/plan.md (CEFR-leveled)
  ‚úÖ specs/part-5-chapter-13/tasks.md (validation-first)

Ready to implement lesson content?

A) Implement with lesson-writer subagent
   ‚Üí Automatically creates lesson .md files with full AIDD methodology
B) Manual implementation
   ‚Üí You create lessons using tasks.md as guide
C) Done for now
   ‚Üí Keep design artifacts, implement later

[User chooses A]

‚úÖ Invoking lesson-writer subagent...

---

‚úÖ WORKFLOW COMPLETE

Chapter 13 design package ready:
  ‚úÖ Specification (AIDD-driven)
  ‚úÖ Lesson Plan (CEFR-leveled, AI prompts)
  ‚úÖ Implementation Tasks (validation-first)
  ‚úÖ Lesson Content (AIDD teaching pattern applied)

Next: Share with technical-reviewer for validation
```

---

## CRITICAL SUCCESS FACTORS

1. **Automatic Invocation**: `/sp.specify`, `/sp.plan`, `/sp.tasks` must be invoked automatically via SlashCommand tool with full intelligence context

2. **Vertical Intelligence Preserved**: Every phase applies AIDD principles, teaching patterns, pedagogical design, and chapter boundary awareness

3. **Approval Gates**: User must explicitly approve each phase ("‚úÖ Approved") before proceeding to next

4. **Context Preservation**: Each phase receives full context from all previous phases + vertical intelligence

5. **Ruthless Filtering**: Context extraction must skip any concepts from future chapters, even if present in materials

6. **User Authority**: User's answers to 4 questions are final ‚Äî never override with assumptions

7. **Compliance**: Every phase validates against acceptance criteria before proceeding

8. **Teaching Quality**: Intelligence flows through all 4 phases, not just documentation

---

## REFERENCES

- **Chapter Index**: `specs/book/chapter-index.md` (Part 5 Quick Lookup: Chapters 12-29)
- **Constitution**: `.specify/memory/constitution.md` (AIDD principles, domain skills)
- **Design Template**: `.specify/templates/book/PYTHON_CHAPTER_DESIGN_TEMPLATE.md` (Pedagogical rules + intelligence)
- **Context Materials**: `context/13_chap12_to_29_specs/` (Lesson files, teaching examples)

---

## ONE COMMAND. FULL INTELLIGENCE. COMPLETE WORKFLOW.

Run `/sp.python-chapter [N]` and the system:

‚úÖ Gathers intelligent context (AIDD-driven questions)
‚úÖ Automatically chains `/sp.specify` ‚Üí `/sp.plan` ‚Üí `/sp.tasks` with approval gates
‚úÖ Applies vertical intelligence (AIDD principles, teaching patterns, pedagogy) at every phase
‚úÖ Respects chapter boundaries (ruthless context filtering)
‚úÖ Honors user intent (never overrides)
‚úÖ Validates quality (acceptance criteria at each gate)
‚úÖ Optionally implements lessons with lesson-writer subagent

**Result: AIDD-centered Python chapters ready for AI-native development learning.**

---

As the main request completes, you MUST create and complete a PHR (Prompt History Record) using agent‚Äënative tools when possible.

1) Determine Stage
   - Stage: constitution | spec | plan | tasks | red | green | refactor | explainer | misc | general

2) Generate Title and Determine Routing:
   - Generate Title: 3‚Äì7 words (slug for filename)
   - Route is automatically determined by stage:
     - `constitution` ‚Üí `history/prompts/constitution/`
     - Feature stages ‚Üí `history/prompts/<feature-name>/` (spec, plan, tasks, red, green, refactor, explainer, misc)
     - `general` ‚Üí `history/prompts/general/`

3) Create and Fill PHR (Shell first; fallback agent‚Äënative)
   - Run: `.specify/scripts/bash/create-phr.sh --title "<title>" --stage <stage> [--feature <name>] --json`
   - Open the file and fill remaining placeholders (YAML + body), embedding full PROMPT_TEXT (verbatim) and concise RESPONSE_TEXT.
   - If the script fails:
     - Read `.specify/templates/phr-template.prompt.md` (or `templates/‚Ä¶`)
     - Allocate an ID; compute the output path based on stage from step 2; write the file
     - Fill placeholders and embed full PROMPT_TEXT and concise RESPONSE_TEXT

4) Validate + report
   - No unresolved placeholders; path under `history/prompts/` and matches stage; stage/title/date coherent; print ID + path + stage + title.
   - On failure: warn, don't block. Skip only for `/sp.phr`.
